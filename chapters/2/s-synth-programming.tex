\section{Synthesizer Programming}
Users generally have two options when trying to generate a desired sound on a synthesizer: they can build up the sound from scratch by adjusting parameters, or they can use a preset parameter setting designed by someone else. Many users also use presets as a starting point and manually adjust parameters to tune the sound \cite{krekovic2019insights}. Synthesizer programming refers to the process of manually adjusting parameters, whether starting from scratch or a preset. Programming a rich sound is considered an art \cite{russ2012sound}, and the quality of the sounds designed by Carlos and Tomita are one of the reasons their work achieved critical acclaim \cite{jenkins2019analog}. Specific techniques for programming synthesizers have lead to the production of sounds that define genres of music, especially electronic music, such as the "wobble bass" sound characteristic of dubstep. [What else can I add here to describe the importance of sound design? Is there anything else?]

\subsection{Challenges}
In the previous section on synthesizer control interfaces, \S\ref{sec:control_interfaces}, three different dimensions of sound were introduced: pitch, loudness, and timbre. Pitch and loudness are uni-dimensional and have relatively simple mappings to parameters \cite{seago2004critical}. The remaining parameters on a synthesizer, which is the vast majority of them, are used to specify the timbre of the resulting sound. This means that the primary task of programming a synthesizer is using a control interface to design the timbre of a sound. But what is timbre? The ANSI definition describes it as the attribute of auditory sensation that allows it to be distinguished from other sounds at the same pitch and loudness \cite{american1973american}. This definition doesn't tell us very much about what timbre is, as opposed to what it is not. Understanding precisely what musical timbre \textit{is} has presented itself as challenging problem \cite{krumhansl1989musical} and significant research has been conducted to try to answer this \cite{McAdams2019}. The spectrotemporal conception of timbre [cite Risset] describes timbre as a series of time-varying spectrums. Building on this, Grey introduced the concept of \textit{Timbre Space} \cite{grey1977multidimensional} as a multidimensional representation of timbre. Risset and Wessel explore timbre in the context of sound synthesis and emphasize the importance of considering the evolution of frequencies over time \cite{risset1999exploration}. 

- What can we draw from this: Programming a synthesizer is specifying how a spectrum evolves over time. It is impractical to do this directly considering the number of parameter values that would need to be set and the values themselves are not easily subjectively interpretable. Different synthesis techniques provide methods for accessing vast regions of the space possible timbres using a more compact set of parameters. 

The complexity of defining what timbre is and how we can accurately represent it highlights one of the challenges of synthesizer programming: users are tasked with navigating a complex multidimensional perceptual space that doesn't have clearly defined boundaries or axes. 

Synthesizer control interfaces provide the means for navigating this space. Most manufacturers avoid venturing into the vague territory of providing perceptually motivated controls and instead allow the underlying synthesis engine to dictate the design \cite{seago2004critical}. As a result, timbre control is mostly specified by a large number of numerical parameters that are unique to the synthesis technique \cite{ethington1994seawave}. Allan Seago describes some of the challenges in programming synthesizers based on various synthesis techniques \cite{seago2013new}:

\begin{quote}
    Some [synthesis techniques], like subtractive synthesis, offer controllers which are broadly intuitive, in that changes to the parameter values produce a proportional and predictable change in the generated sound. Other methods, however, are less easily understood. FM synthesis, for example, is a synthesis method that may be viewed as essentially an exploration of a mathematical expression, but whose parameters have little to do with real-world sound production mechanisms, or with perceived attributes of sound.
\end{quote}

Both Wendy Carlos and Isao Tomita were both masters at programming synthesizers. They learned the connection between the parameters of the synthesizers and how to interconnect modules to create the rich timbres that made their music so special. This involved developing a deep understanding of the technical details of the synthesis engine, how the parameters affected synthesis, and how to proficiently navigate the timbre space of their synthesizers. A recent study conducted by Gordan Krekevi\'{c} sought to elucidate how a more general population of synthesizer users \cite{krekovic2019insights}. 

.


Most traditional synthesizer interfaces avoid venturing into the vague territory of defining timbre and provide control that 


% McAdams \cite{McAdams2019} identifies timbre as a perceptual property of sound and overviews two common conceptions of timbre. The first is a spectrotemporal conception which identifies 

% - Introduce perceptual representation. 

% A perceptual representation of timbre is thoug

% McAdams \cite{McAdams2019} identifies timbre 


% Early work on musical timbre focused on the periodic nature of tones and concluded that the frequency spectrum, derived from Fourier analysis, was the sole contributor to timbre [cites]. A spectrotemporal conception of timbre was then introduced, which identified the temporal aspects and evolution of a spectrum as being critical. The idea of timbre space was proposed by Grey \cite{grey1977multidimensional} which introduced a multidimensional conception of timbre. Risset and Wessel \cite{risset1999exploration} explore musical timbre in the context of various audio synthesis algorithms.

% - Introduces a challenges -- timbre is challenging to define. Perceptual attribute of sound.

% Musical timbre is a complex perceptual property of sound \cite{McAdams2019} and has been 

% and challenging to understand \cite{krumhansl1989musical}. The ANSI definition of timbre is that it is the attribute of auditory sensation that allows it to be distinguished from other sounds at the same pitch and loudness \cite{american1973american}. This definition doesn't tell us very much about what timbre is, as opposed to what it is not. A significant body of research has been dedicated to 



% \cite{McAdams2019} Perceptual representations of timbre.

% - This looks interesting: https://link.springer.com/chapter/10.1007%2F978-3-030-14832-4_2

The artistry in synthesizer programming lies in the specification of parameters to create new musical timbre.

- Seago defines the procress of programming a synthesizer as selecting the timbre. \cite{seago2004critical}

- Synthesizer programming is essentially like trying to navigate the space of timbre.
- Risset and Wessel \cite{risset1999exploration} on timbre and synthesis.
- What can we say about timbre space? How can we define timbre? \cite{grey1977multidimensional}. Grey created a three-dimensional representation of timbre.
- \cite{bates2021interface} - looks at interfaces of modular synthesizers (maybe better in control interfaces?) 
- \cite{d2016interface} interface of software synthesizers and smart phones?

A skilled sound designer is able to interact with the control interface and craft sounds to fit the needs of their creative project. This process is referred to as programming a synthesizer. 

Both Carlos and Tomita excelled at patching synthesizer modules together and tuning the parameters of individual modules to create new sounds to orchestrate their performances. This process ... it's art! Blah blah blah. But also these folks are artists and virtuosos.

- Challenges identified in \cite{ethington1994seawave}: Timbre is most commonly specified by a large collection of numerical parameters peculiar to a particular synthesis technique."
- Challenges with synthesizer programming UI design: \cite{seago2013new}. -- "Some, like subtractive synthesis, offer controllers which are broadly intuitive, in that changes to the parameter values produce a proportional and predictable change in the generated sound. Other methods, however, are less easily understood. FM synthesis, for example, is a synthesis method that may be viewed as essentially an exploration of a mathematical expression, but whose parameters have little to do with real-world sound production mechanisms, or with perceived attributes of sound." -- There are some other really good bits about navigating the timbre space and non-linearities.
- \cite{seago2004critical} Thus, under most current systems, the user is obliged to express directives for sound specification in system terminology, rather than in language derived from the user domain. Three types of synthesizer interfaces: parameter selection in a fixed architecture, architecture specification and configuration, and direct specification of physical characteristics of sound.
- Context on synthesizer programming \cite{jenkins2019analog}
- Russ describes the programming component intrinsically creative.
- When we talk about programming synthesizers we are referring to the task of selecting parameter settings for a synthesizer in order to achieve a desired sound

- Talk about the nature of this task. I think in that krekovic study there was something about this process? That this can be done in an exploratory way that ppl enjoy that process. \cite{krekovic2019insights}
- 122 participants. 71\% had ten or more years of experience using synthesizers and only 2.7\% claimed they were novice users. Also, a majority of users had some formal training as musicians. So this study has quite a high representation of users who are experienced, as opposed to studying individuals who are novices. Musical training was only a weak indicator of experience using synthesizers. Most users most often create a synth patch from scratch or modify an existing one and only sometimes use presets with no modification. Interestingly there was no correlation with experience or music education. All users, regardless of experience or musical knowledge most often tweak the parameters of synthesizers.
- Four impediments to manually programming a synthesizer: 1) It can be time consuming, 2) it can distract them from focusing on music, 3) it can be difficult and non-intuitive to learn how to use a particular instrument, and 4) it rarely leads to desirable results. Participants agreed with the first three statements. Most participants disagreed with the fourth statement, but users with less experience were more likely to agree. Considering the average experience level of the group, these results highlight the challenges with synthesizer programming in the context of creating music.

- Even so, it can still be quite a challenging task.

% Potentially introduction material
Programming audio synthesizers is challenging and requires a technical understanding of sound design to fully realize their expressive power. Traditional synthesizers can have over 100 parameters that affect audio generation in complex, non-linear ways. One of the most commercially successful audio synthesizers, the Yamaha DX7, was notoriously challenging to program. Allegedly nine out of ten DX7s coming into workshops for servicing still had their factory presets intact \cite{seago2004critical}.

\subsection{Opportunities}
Krekovi\'{c} \cite{krekovic2019insights} participants were also asked to rate the perceived helpfulness of improvements to synthesizer  interfaces. Four different systems were proposed: 1) random presets are generated within a category, 2) a user provides a description of a the desired sound and a preset is generated for them, 3) a user provides an example sound and the system generates a presets to sound similar, and 4) more intuitive interactive user interface. Participants thought that proposed systems 3 and 4 would be helpful and systems 1 and 2 would be slightly helpful.
