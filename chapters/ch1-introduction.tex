\startfirstchapter{Introduction}
%! Simplify this!! Cut out the research context stuff I think or at least make things much tighter.
\label{chapter:introduction}
%[Would be cool to say something about the THX sound here, that'd be a neat introduction]
The sound synthesizer is a familiar tool for many musicians and audio practitioners working in music, film, video games, and other industries related to audio production. Despite its widespread use, the task of programming new sounds into a synthesizer is complex and requires a thorough understanding of sound design principles and technical details. It is not uncommon for a software synthesizer to have thirty or more parameters displayed on a user interface and labelled using technical names specific to the particular device \cite{rasmussen2018evaluating}. Synthesizer programming involves manually adjusting these parameters to achieve a desired sound. The task is further complicated by the fact that modifications to these parameters are often not intuitively reflected in the end sonic result. The implication of these constraints is that there is a large learning curve associated with becoming an effective synthesizer programmer and even experienced musicians and audio practitioners can find the task of programming a synthesizer disruptive to their creative process \cite{krekovic2019insights}. This is referred to as the ``synthesizer programming problem."

%[This is referred to as the "synthesizer programming problem" < is this true? You use the term later on and I like it as a wrap-up to this intro! :)]

The central goal of this thesis is to support the development of methods that address the challenges of synthesizer programming. These methods have the potential to make synthesizers more accessible and enable more individuals to be creative more often. The benefits of engaging in the creative process on a regular basis have been proven \cite{conner2018everyday} and music technology has the power to enable individuals to express themselves in domains that were previously unavailable to them \cite{tavana2015democracy}. Developing methods that lower the barrier to entry can allow novices to work with synthesizers in ways that would have previously been unavailable to them. It would also enable them to gain experience more quickly and easily, and remove impediments to their creative process.

Automatic synthesizer programming is the field of research that involves the development of techniques and tools to address the challenges of synthesizer programming. It is inherently interdisciplinary and draws from fields including digital signal processing, creativity support, music interaction, artificial intelligence, and machine learning. Work in automatic synthesizer programming dates back to the 1970s \cite{justice1979analytic}. A large body of research that explores a variety of approaches for improving and automating the task of synthesizer programming has followed. One central focus of automatic synthesizer programming has been \textit{sound matching}, or \textit{inverse synthesis}, which involves predicting synthesizer parameters that will recreate a target sound as closely as possible \cite{horner1993machine}. A number of other methods have also been proposed such as using descriptive words \cite{seago2013new} or vocal imitations \cite{cartwright2014synthassist}. Despite the breadth of work on the topic, the task of automatic synthesizer programming remains a complex problem with many open questions. The continued desires expressed by synthesizer users for improved methods of synthesizer programming points to the need for further work in this field \cite{krekovic2019insights}.

% Music information retrieval (MIR), a related field of study that grew out of the need for improved methods for organizing and navigating large collections 

The main goal of this thesis is to explore and contribute to the algorithmic and user interaction aspects of the synthesizer programming problem. The challenge with synthesizer programming is essentially a human-computer interaction (HCI) problem; the conceptual gap between synthesizer parameters and the associated auditory result is large and users are forced to bridge that gap themselves, which involves a steep learning curve. 
% The task of manipulating synthesizer parameters to achieve a desire audio result is a daunting and users are forced to develop this skill themselves, essentially through trial and error, which involves a steep learning curve.
Novel user interaction paradigms help users communicate ideas to synthesizers in ways that support their creativity, such as using example sounds \cite{horner1993machine, yee2018automatic}, vocal imitations \cite{cartwright2014synthassist, zhang2017iminet}, or descriptive words \cite{seago2013new}. Algorithmic techniques involving artificial intelligence and machine learning, including deep learning, have been used to create new user interfaces for synthesizer programming and are also a focus of this thesis. Inverse synthesis, which synthesizer users have identified as helpful \cite{krekovic2019insights}, has especially benefited from advancements in deep learning in recent years. In this thesis, several techniques for inverse synthesis are evaluated, and a new approach that combines the strengths of evolutionary programming and deep learning is introduced. 
% Getting a bit wordy
% and achieves high-quality results in less than half the time of the previous state-of-the-art method on a benchmark frequency modulation (FM) synthesis sound matching task. 
A novel interface for exploring synthesizer sounds using two-dimensional visualizations is presented in chapter \ref{chapter:synth-explore}, along with a design framework for automatic synthesizer interactions.

A secondary goal of this thesis is to support continued development in the field of automatic synthesizer programming and to encourage collaboration and reproducible research \cite{vandewalle2009reproducible}. A related field of study, music information retrieval (MIR), has benefited from open-source software, open datasets, and shared evaluations.
%[cite] has benefitted from benchmark tasks, open datasets, and evaluations including the music information retrieval exchange (MIREX) [cite]. Additionally, open source software that has supported research in MIR including Marsyas [cite] and Librosa [cite] have enabled the growth the of field. 
However, there are few examples of similar shared resources and collaboration in the field of automatic synthesizer programming. The open-source software and datasets that were developed by the author as a part of this thesis are inspired by the contribution of similar resources to the field of MIR.  Chapter \ref{chapter:spiegelib} presents an open-source library -- named \textit{spiegelib} after American electronic music composer Laurie Spiegel -- for sharing and evaluating inverse synthesis algorithms. Chapter \ref{chapter:torchsynth} presents a large-scale multi-modal synthesizer sound dataset called \textit{synth1B1} and an open-source GPU-enabled modular software synthesizer called \textit{torchsynth} that is used to generate synth1B1. synth1B1 and torchsynth are designed to assist in the investigation of the complex relationship between synthesizer parameters and associated auditory output.


\section{Research Questions}
The main challenges in synthesizer programming arise from the disconnect between synthesizer parameters and the associated auditory output. The result of this disconnect is that synthesizers are difficult to use, have a high-barrier to entry, and impede the creative process of creating music and producing audio. The purpose of this thesis is to address these challenges. The main research question is:

\begin{quote}
    How can designers of synthesizer programming interfaces enable more people to be more creative more often?
\end{quote}

Fundamental to answering this question is developing an understanding of the complex relationship between synthesizer parameters and the associated auditory result. Automatic synthesizer programming seeks to develop this understanding and bridge the conceptual gap between synthesizer parameters and the associated auditory output. More specific sub-questions that have motivated the work presented in this thesis are listed in the sections below.

\subsection{Automatic Synthesizer Programming}
What is the field of automatic synthesizer programming? What makes synthesizer programming so challenging and how do those challenges inform research focused on improving and automating it? A significant amount of previous work has been conducted in this field covering a large number of different approaches. How can we organize the body of previous work to help understand the problem and the approaches that have been taken?

\subsection{Inverse Synthesis}
A substantial portion of previous work in automatic synthesizer programming has focused on algorithmic techniques for inverse synthesis. Many early approaches used evolutionary programming and more recent techniques use deep learning. How do evolutionary approaches compare to deep learning? What are the strengths and weaknesses of each of these approaches? What types of deep learning models are best suited for inverse synthesis? How can we support open evaluation and reproducibility of these approaches?

\subsection{Representing Synthesized Sounds}
A key component of developing automated synthesizer programming systems is being able to effectively answer the question: how similar is sound X to sound Y? How do we represent audio computationally and how do we define a metric that can help in answering this question?

\subsection{Generating Synthesized Sounds}
Datasets of synthesized audio and associated parameters are important for research on understanding the relationship between synthesizer parameters and the resulting audio, as well as for development of machine learning methods for synthesizer programming. The simplistic approach is to uniformly sample the parameters of a particular synthesizer. However, is uniformly sampling parameters the best approach to generating parameter selections? The associated sounds in many cases do not represent sounds that a human would have programmed in a musical context. How can we sample synthesizer parameters to generate sounds that sound as if a human programmed them?

\subsection{Developing Supportive Tools}
How do we create effective and intuitive user interfaces to support synthesizer programming? To what extent should the tool automate the process of synthesizer programming? What interaction paradigms best support creativity? Which algorithmic methods for automatic synthesizer programming can best support creativity?


%but other approaches have been proposed. What are the different user interaction approaches that have been explored? 
%
%How can one organize the body of previous work to help understand the problem and approaches that have been taken?
%
%\subsection{}
%
%
%- What is the field of automatic synthesizer programming? How can we organize the body of previous work to better understand the problem and approaches that are being taken?
%-- Formalize the challenge of synthesizer programming and frame it as a human computer interaction problem. A survey of the approaches from a user interaction perspective is then provided.
%
%- Inverse synthesis research has dominated the landscape of previous work? How does these various techniques compare?
%-- There are no standardized evaluation metrics or software libraries that support 
%
%- Understanding the synthesizer parameter space:
%-- The connection between the parameters on a synthesizer 
%
%- Designing supportive tools
%-- How do we approach designing applications that support musicians and other synthesizer users in using synthesizers?

\section{Summary of Contributions}
The main contributions of this thesis are the following:

\begin{enumerate}
    \item A survey and taxonomy of related work in automatic synthesizer programming from a user interaction perspective.
    \item An open source software library designed to support the development, sharing, and evaluation of automatic synthesizer programming techniques.
    \item An evaluation of several techniques for inverse synthesis conducted on a benchmark frequency modulation (FM) synthesis task
    \item A novel inverse synthesis technique that combines deep learning and a multi-objective genetic algorithm.
    \item Three open datasets, including one large-scale billion sound+parameter dataset designed to support further research in synthesizer programming and deep learning training / pre-training.
    \item An open-source GPU-enabled modular synthesizer for efficiently generating the billion sound dataset on-the-fly and for supporting efficient research on synthesis algorithms.
    \item A design framework for developing tools to support synthesizer programming.
    \item A prototype automatic synthesizer programming tool designed to support exploration using two dimensional visualization of sounds based on sound similarity.
\end{enumerate}

\section{Thesis Structure}
\begin{itemize}
    \item Chapter \ref{chapter:background} provides background information and historical context for audio synthesizers. The challenges and opportunities associated with synthesizer programming are outlined.
    \item Chapter \ref{chapter:asp-background} contains an overview of the field of automatic synthesizer programming. Synthesizer programming is framed as a human computer interaction problem and the various interaction paradigms and algorithmic techniques proposed in previous work is reviewed.
    \item Chapter \ref{chapter:spiegelib} describes a software library the author has created to support research in automatic synthesizer programming and to serve as a repository for sharing and comparing approaches. This library was used for the experiments discussed in chapter \ref{chapter:inverse_synth_experiment}.
    \item Chapter \ref{chapter:inverse_synth_experiment} describes an inverse synthesis experiment that compares recent approaches as presented in the literature. Several deep learning models and genetic algorithms were compared on a baseline FM synthesis problem. A novel hybrid approach is also proposed.
    \item Chapter \ref{chapter:torchsynth} introduces a large-scale synthesizer dataset and a GPU-accelerated modular synthesizer called torchsynth that were designed to support further research in automatic synthesizer programming.
    \item Chapter \ref{chapter:synth-explore} outlines a novel automatic synthesizer programming application that utilizes two-dimensional visualization of sounds to support exploration of synthesizer sounds. The application was developed with novice users in mind and is based on a set of design principles proposed as a framework to support the design of assistive synthesizer programming tools.
\end{itemize}

% My main statement about the introduction is:
% \textit{"keep it short and write it last".} The main features should be as follows:
% \begin{enumerate}
% \item {3-4 pages at most;}
% \item {Start with a VERY short statement of the problem (2-3 sentences) - the problem should be stated, not described, as there will be a whole chapter for that;}
% \item {State why the problem is important, its impact, how well it has been studied recently, its application (3 sentences) - this should be again a brief motivation, leaving a full impact description to later in the document;}
% \item {Give a sketch of the new approach - there will be a whole chapter with all the details, now just impress the reader about what is the new approach, just as you would do if your boss asked you at work during an elevator ride;}
% \item {Sketch the main new ideas of the new approach - again briefly, just get the reader interested;}
% \item {Give a short statement regarding the results, nothing too elaborate, but certainly you should blow your horn and make sure that the reader is intrigued;}
% \item {Interspersed in all the writing above do not forget the marketing angle, trying to suggest forcefully why the reader should keep reading;}
% \item {Give an outline of what is to come in the organization of the thesis overall - you will find one below for this document.}

% \end{enumerate}

% Finally the strong suggestion is write the introduction chapter last. It will be faster, you will know what to say as the rest is already there, and the abstract, introduction and conclusion will be a mirror and complement of each other. You may well ask where to start writing your thesis. My view is included in the organization below.


% Automated methods for music production -- why do we need it? The main thread here is looking at methods for exploring sound spaces. How can we improve this approach? Potentially need a bit on timbre -- the timbre space article could be really good.

% General introduction. Distinction between creative mir, intelligent music production, automatic synthesizer programming.

% Democratization of sound \cite{tavana2015democracy}

% Moffat and Sandler examine approaches to intelligent music production \cite{moffat2019approaches}.

% \cite{krekovic2019insights} user study examined synthesizer user habits and pointing to need for further work in automatic synthesizer programming

% \section{Automating Synthesizers}
% The use of sound synthesizers in the fields of music composition, production, and performance is widespread, but the task of programming a synthesizer is complex and requires a thorough understanding of technical details. It is not uncommon for a software synthesizer to have 30+ parameters displayed on a user interface (UI) and labelled using technical names \cite{rasmussen2018evaluating}. Manually programming sounds using such a large set of parameters is a daunting task. Synthesizer programming is further complicated by the fact that modifications to parameters are often not intuitively reflected in the end sonic result. This disconnect can be disruptive to the creative process. Automatic synthesizer programming (ASP) is the field of research focused on addressing these challenges in programming synthesizers.

%  Early ASP research emerged in the late 1970s with work that focused on the use of analytic methods to estimate the parameters for frequency modulation (FM) synthesis \cite{justice1979analytic}. That work was an example of synthesizer sound matching in which a system estimates synthesizer parameters to replicate a target sound. Since then a large volume of work on synthesizer sound matching has been published and has explored a variety of synthesis techniques and algorithmic methods. One popular approach is the use of evolutionary algorithms \cite{horner1993machine, mitchell2007evolutionary, yee2007evolving, yee2008synthbot, heise2009automatic, roth2011comparison, tatar2016automatic, smith2017play}. More recently, deep learning techniques have been explored \cite{yee2018automatic, barkan2019inversynth, esling2020flow}. Other methods that have been studied include semantic descriptions \cite{ethington1994seawave, johnson2006timbre, krekovic2016algorithm}, interactive methods \cite{johnson1999exploring, dahlstedt2001creating, yee2016use}, and sound matching with vocal imitations \cite{mcartwright2014, zhang2018visualization}.
 
%  A recent user study conducted by Krekovi{\'c} et al. confirmed the desire among synthesizer users for improved means of working with their synthesizers \cite{krekovic2019insights}. 
%  %Users identified approaches they felt would be particularly beneficial, which included automatic sound matching and improvements to user interface design. 
%  While recent research has produced promising results, automatically programming a modern software synthesizer still presents challenges. Current evolutionary techniques face issues including time complexity \cite{tatar2016automatic}, while recent deep learning approaches have challenges in consistently producing accurate reproductions \cite{yee2018automatic}. The desires expressed by the users in Krekovi{\'c} et al.'s study, coupled with the need for further research and improvement noted in the existing body of work, point to the need for further development in ASP.
 
%  The work presented here attempts to continue this development, and promote collaboration and reproducibility in ASP research through the introduction of \mintinline{python}{spiegelib}, an open-source library written in the Python programming language. Vandewalle et al. argue that reproducibility in computational science research increases the impact of a work and they provide a framework for evaluating the quality of reproducibility \cite{vandewalle2009reproducible}. The aim of \mintinline{python}{spiegelib} is to provide a platform for researchers of automatic synthesizer programming to develop, test, and share implementations in a way that promotes reproducibility at the highest level. \mintinline{python}{spiegelib} stands for Synthesizer Programming with Intelligent Exploration, Generation, and Evaluation Library. The name \mintinline{python}{spiegelib} was chosen to pay homage to Laurie Spiegel, an early pioneer in electronic music composition. Laurie Spiegel is known for utilizing synthesizers and software to automate certain aspects of the music composition process. Her philosophy for using technology in music serves as a motivation for the \mintinline{python}{spiegelib} software library: "I automate whatever can be automated to be freer to focus on those aspects of music that can't be automated. The challenge is to figure out which is which." \cite{hinkle2006women}


% Introduce automatic synthesizer programming. Tie it to intelligent music production \cite{moffat2019approaches} \cite{de2017ten} and creative MIR \cite{humphrey2013brief}.

% \subsection{History}
% DX7 plays an important role here - made synthesizers more widely available but programming them was notoriously difficult. 9 out of 10 DX7s that went in for service had factory presets intact (Reference needed). Almost immediately researchers became interested in learning how to estimate synthesizer presets for FM algorithms which spread into non-linear synthesis methods, then wavetable synthesis, then physical modelling, granular, additive. (References needed for synthesis types). 

% Justice 1979 \cite{justice1979analytic}  - Automatic FM matching. Early example of looking try to find a coarse match of FM generated tone to the parameters (ie examples were FM generated). Beauchamp 1982 \cite{beauchamp1982synthesis} - Frequency domain matching of FM tones. Included in a larger study involving spectral centroid matching in nonlinear synthesis. Early automatic spectral match. Also looked at non-linear and filter model. Found that non-linear/filter model worked better. Payne 1987 \cite{payne1987microcomputer} Looked at automatic FM tone matching to the acoustic sounds - using DX7 and hilbert transform as well. Delprat et al. 1990 \cite{delprat1990parameter} using wavelets for non-linear synthesis parameter estimation. Horner at al. early example of automatic synthesizer preset generation in 1993 \cite{horner1993machine}. Attempted to match FM parameters with a harmonic signal using a genetic algorithm. Horner et al. then applied denetic algorithm applied to wavetable synthesis \cite{horner1993methods}. Vouri and V{\"a}lim{\"a}ki on parameter estimation for physical modelling of flute tones \cite{vuori1993parameter}. Fujinaga and Vantomme 1994 Genetic Algorithms applied to granular synthesis \cite{fujinaga1994genetic}. SeaWave by Ethington and Punch, a synthesizer that can be controlled using vocabulary. Has a pre-defined set of descriptors \cite{ethington1994seawave}. Miranda 1995 paper proposing a system utilizing AI to automatically program a generic synth using vocabulary \cite{miranda1995artificial}. Horner 2003 paper reviews FM and wavetable synthesis as well as approaches to automatic parameter matching \cite{horner2003auto}.


% \section{User Interface Design}
% \subsection{Synthesizer Programming}
% Seago identified disconnect between the language of users and the language used in synthesizer interfaces \cite{seago2004critical}. Recent work focussed on synthesizer UIs \cite{rasmussen2018evaluating}. Krekovic in a 2019 study of 112 synthesizer users, reported most participants reported feeling like the process of modifying or creating new synthesizer patches was a challenging process and not intuitive \cite{krekovic2019insights}. A majority of users' felt like more intuitive interfaces was the area that would be most beneficial in helping them during the process of programming a synth. Users also felt that sound matching would be helpful. Krekovic identifies that relatively little research has been completed in the area of synthesizer user interfaces. This is reflective of recent research focussed on human computer interface and ui design for music applications \cite{pardo2019learning}\cite{knees2019intelligent}.


%One of the main goals of this thesis is to organize the body of 
%
%
%It is an inherently interdisciplinary topic, drawing from advancements in fields including digital signal processing, creativity support, music interaction, artificial intelligence, and machine learning. With the rise of personal computers and the internet there was a movement towards digital methods for producing, distributing, and consuming audio in the 80s and 90s [cite]. Audio production methods transitioned to software and a plethora of tools have been developed that have enabled everyday consumers to write and record music outside of large studios [cite]. There are currently over 500 individual software synthesizers available on the KVR online database of audio softare [footnote].







%[Add a sentence or two in here about what I actually present in this thesis]
%- Overview of the field of automatic synthesizer programming
%- Sharing is caring
%- Specific emphasis is placed on encouraging reproducible research and open sharing in the field. An evaluation of several recent approaches is provided in an open-source framework designed to facilitate sharing and open evaluation
%
%\section{Research Context}
%\subsection{Music and Audio Production}
%I want to introduce MIR and IMP here.
%With the rise of personal computers there was a movement towards digital methods for producing, distributing, and consuming music in the 80s and 90s [cite?]. As computers became more powerful and consumers started to accumulate large collections of digital music, the need for improved methods for organizing and browsing these collection became apparent. Music information retrieval (MIR) is the field of study that was born out of the need to navigate these increasingly large collections of digital music [cite]. Simultaneously, many of the processing for recording and producing music were also being moved onto computers. The development of affordable computers that could run digital audio workstations (DAWs) along with a proliferation of companies developing audio production software has resulted in the decentralization of music production. Traditionally restricted only to those who could afford to work in expensive recording studios had access to high-quality recording equipment [cite for the record production text]. Affordable technology has enabled virtually anyone to write, record, and produce their own music; grammy award winning records are now being written and produced in bedrooms [find cite for eilish]. Despite this, and the unprecedented amount of audio software available to consumers, there is still a large learning curve associated with learning to use audio software. Intelligent music production (IMP) is a field of study related to MIR that has grown to address these challenges and focuses on creating improved user interactions and automatic aspects of the music production process \cite{de2017ten, moffat2019approaches}. 
%
%\subsection{Automatic Synthesizer Programming}
%Audio synthesizers have had a similar trajectory thanks to the development of affordable digital and software methods. The Yamaha DX7, released in 1983 [fact check], was one of the first affordable digital synthesizers and went on to become one of the best sellinf synthesizers of all. It was also notoriously difficult to manually program and seven out of eight units that went in for service had their factory presets intact [cite - seago]. Similar to other audio production tools, the development of software synthesizers that could run on personal computers has lead to an increase in the availability of these devices as well as a desire to learn how to use them. There are over 500 different software synthesizers listed on the KVR website and 147 different videos courses available for sale on the Groove3 online education platform teaching synthesizer programming\footnote{\url{https://www.groove3.com/browse}}. This 
%
%
%Automatic synthesizer programming is the field of research centered around addressing the challenges with synthesizer programming. It is an inherently interdisciplinary topic, drawing from advancements from fields including digital signal processing, creativity support, music interaction, artificial intelligence, and machine learning.
%
%on the topic of inverse synthesis, also referred to a sound matching, which is focused on automatically finding parameters for a synthesizer to reproduce a target sound as closely as possible. Work was first published on this topic in the late 1970s \cite{justice1979analytic} and has grown in popularity in recent years in parallel with advancements in deep learning \cite{lecun2015deep}. The term automatic synthesizer programming was coined by Matthew Yee-King in 2008 and to refer to synthesizer sound matching \cite{yee2008synthbot}.
%
%The term automatic synthesizer programming was coined by Matthew Yee-King in the 
%
%% This is maybe a bit more like introduction material?
%% Synthesizers have become ubiquitous in audio production and entire genres of music have been developed around their use. Bebe and Louis Barron produced the first electronic film score for the movie "Forbidden Planet" in 1955 using synthetic sounds. Since then the use of synthesizers for movies and video games has also become common-place.
%
%- Where can this Laurie Spiegel quote fit in?
%"I automate whatever can be automated to be freer to focus on those aspects of music that can't be automated. The challenge is to figure out which is which." - Laurie Spiegel \cite{hinkle2006women}
%
%% Is this maybe introduction material?
%- How can I keep this section more simple?
%
%The growing accessibility of hardware and software synthesizers has resulted in an unprecedented number of audio practitioners and hobbyists purchasing and desiring to learn how to program synthesizers. This is reinforced by the fact that there are currently 147 different videos courses available for sale on the Groove3 online education platform teaching synthesizer programming for various virtual instruments\footnote{\url{https://www.groove3.com/browse}}.
%
%
%In a recent study, users reported on the challenges associated with learning to user various synthesizers and a expressed a desire for improved user interaction methods \cite{krekovic2019insights}. The growth in interest in amongst musicians to learn to program synthesizers, along with desires for more intuitive ways to work with them points to the need for additional research in this area. This serves as motivation for the research conducted in this thesis.
%
%Maybe this should go above in introduction.
%[rmba conversations] \textit{et al.} identified that music producers often feel like the task of browsing for sounds using traditional methods is tedious and takes them out of the creative flow. Similarly, [krekovic] \textit{et al.} identified that synthesizer users felt like programming sounds in software synthesizer interfaces was complex and required time and effort. Users' in their study expressed
%
%% Can I add some context here for MIR, Intelligent Music Production, and such? Or does this go in a research context section? Still want to keep this chapter snappy.
%- Understand the field of automatic synthesizer programming,
%
%\subsubsection{Availability of Synthesizers}
%- Democratization of audio (What's that reference on GarageBand?) Something about the introduction of synthesizers, then the Yamaha DX7, which was notoriously difficult to program
%- Add in some statistics regarding modular synthesis, KVR, Groove3 -- to provide some context on current trends in synthesizer use and where things are at. 
%
%\subsubsection{Democratization of Sound}
%- Democratization of sound \cite{tavana2015democracy} -- GarageBand bit. Gateway DAW to more complicated software like Ableton Live. Gender aspect to this as well. "The feminist implication of GarageBand definitely encouraged a lot of my female friends to explore something that had previously seemed out of reach." "While it may have introduced a whole lot more people of all genders to an array of options for home recording and self-producing, an overwhelming majority of engineers in studios are still male." Indeed, recent estimates reveal that less than five percent of sound engineers and producers in the music business are women. (Maybe include Amandine's paper here?) 
%- Krekovi\'{c}'s study where a vast majority of users were male
%
%\subsubsection{Gateway Synthesizers}
%Enabling more people to be creative! 
%
%\subsection{Personal Motivation}
%What's my personal motivation for this research?